{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title_introduction"
   },
   "source": [
    "# Multi-Layer Perceptron on MNIST\n",
    "\n",
    "In this unit practical, we will build and evaluate a Multi-Layer Perceptron (MLP) that classifies images from the [MNIST](http://yann.lecun.com/exdb/mnist/) handwritten digit dataset.\n",
    "\n",
    "The notebook is organised into the following steps:\n",
    "1. **Data Loading and Visualization**\n",
    "2. **Define the Network Architecture**\n",
    "3. **Specify Loss Function and Optimizer**\n",
    "4. **Train the Network**\n",
    "5. **Evaluate the Model**\n",
    "6. **Visualize Predictions and Learned Features (t-SNE)**\n",
    "\n",
    "Let's begin by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_loading"
   },
   "source": [
    "## Step 1: Data Loading and Visualization\n",
    "\n",
    "We load the MNIST dataset (both training and test sets) and create data loaders. You can change the `batch_size` or `num_workers` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_loader_setup"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Parameters for data loader\n",
    "num_workers = 0\n",
    "batch_size = 16\n",
    "\n",
    "# Define transformation\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Load datasets\n",
    "train_data = datasets.MNIST(root='DATA', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='DATA', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize_train_data"
   },
   "source": [
    "### Visualize a Batch of Training Data\n",
    "\n",
    "It is always a good idea to inspect your data. The following cell visualizes a single batch of training images along with their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_train_batch"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Get one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.numpy()\n",
    "\n",
    "# Plot the batch of training images with labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, batch_size//2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "define_network"
   },
   "source": [
    "## Step 2: Define the Network Architecture\n",
    "\n",
    "We create an MLP with one hidden layer. The network takes a 784-dimensional flattened image as input and outputs a 10-dimensional tensor, representing class scores for each digit. A sigmoid activation is used after the first fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlp_definition"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # First fully connected layer: from 784 (28x28) to 512 neurons\n",
    "        self.fc1 = [TODO]\n",
    "        # Second fully connected layer: from 512 to 10 neurons (one per class)\n",
    "        self.fc2 = [TODO]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # Apply the first FC layer and sigmoid activation\n",
    "        x = [TODO]\n",
    "        \n",
    "        # Apply the second FC layer (output layer)\n",
    "        x = [TODO]\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize the network and print its architecture\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loss_optimizer"
   },
   "source": [
    "## Step 3: Specify Loss Function and Optimizer\n",
    "\n",
    "We use the cross-entropy loss for this classification task. The optimizer is set to SGD with a learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loss_optimizer_code"
   },
   "outputs": [],
   "source": [
    "# Specify loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_network"
   },
   "source": [
    "## Step 4: Train the Network\n",
    "\n",
    "We now train the network. The following loop runs for a specified number of epochs (adjustable as needed). For each epoch, we clear the gradients, perform a forward pass, compute the loss, backpropagate the error, and update the model parameters. The average training loss for each epoch is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_loop"
   },
   "outputs": [],
   "source": [
    "# Number of epochs for training\n",
    "n_epochs = 5  # For a faster demo; consider using between 20-50 epochs for real training\n",
    "\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Train the model on each batch\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()         # Clear gradients\n",
    "        output = model(data)            # Forward pass\n",
    "        loss = criterion(output, target)  # Calculate loss\n",
    "        loss.backward()                 # Backward pass\n",
    "        optimizer.step()                # Update parameters\n",
    "        train_loss += loss.item() * data.size(0)  # Accumulate loss\n",
    "    \n",
    "    # Calculate average loss over the epoch\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_model"
   },
   "source": [
    "## Step 5: Evaluate the Trained Network\n",
    "\n",
    "After training, we evaluate our network on the test data. The test loop calculates the average test loss and computes per-class as well as overall accuracy. Note that `model.eval()` disables dropout and uses running statistics for batch normalization during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_loop"
   },
   "outputs": [],
   "source": [
    "# Initialize tracking variables for test loss and accuracy per class\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)            # Forward pass\n",
    "        loss = criterion(output, target)  # Calculate loss\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "        \n",
    "        _, pred = torch.max(output, 1)    # Get predictions\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        for i in range(batch_size):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "# Calculate average loss\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "# Print test accuracy for each class\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of {:5s}: {:2d}% ({:2d}/{:2d})'.format(\n",
    "            str(i),\n",
    "            int(100 * class_correct[i] / class_total[i]),\n",
    "            int(class_correct[i]), int(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of {:5s}: N/A (no training examples)'.format(str(i)))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): {:2d}% ({:2d}/{:2d})'.format(\n",
    "    int(100. * np.sum(class_correct) / np.sum(class_total)),\n",
    "    int(np.sum(class_correct)), int(np.sum(class_total))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize_predictions"
   },
   "source": [
    "### Visualize Sample Test Predictions\n",
    "\n",
    "The following cell displays a batch of test images and shows the predicted label alongside the true label. Correct predictions are highlighted in green, whereas incorrect ones are shown in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_test_predictions"
   },
   "outputs": [],
   "source": [
    "# Get a batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Get predictions\n",
    "output = model(images)\n",
    "_, preds = torch.max(output, 1)\n",
    "images = images.cpu().numpy()\n",
    "\n",
    "# Plot the batch of test images with predicted and true labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, batch_size//2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsne_raw"
   },
   "source": [
    "## Step 6: t-SNE Visualization\n",
    "\n",
    "In this section, we perform t-SNE on:\n",
    "1. **Raw Pixel Inputs:** We project the flattened pixel values into 2D space.\n",
    "2. **Learned Features:** We extract the features from the last layer (after `fc2`) using a forward hook and then perform t-SNE on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsne_raw_code"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare the raw pixel data\n",
    "X = torch.stack([img for img, _ in test_data])\n",
    "X_np = X.view(-1, 28*28).numpy()\n",
    "Y = torch.tensor([label for _, label in test_data]).numpy()\n",
    "\n",
    "# Define and apply t-SNE on raw pixel inputs\n",
    "tsne = TSNE(n_components=2, perplexity=30, learning_rate='auto', init='pca', n_iter=300)\n",
    "X_embeded = tsne.fit_transform(X_np)\n",
    "\n",
    "# Plot the t-SNE results\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.scatterplot(x=X_embeded[:, 0], y=X_embeded[:, 1], hue=Y, palette=\"deep\")\n",
    "plt.title(\"t-SNE on MNIST Raw Pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsne_features"
   },
   "source": [
    "### t-SNE on Learned Features (from fc2 layer)\n",
    "\n",
    "We now extract features from the `fc2` layer using a hook, and then visualize these features with t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsne_features_code"
   },
   "outputs": [],
   "source": [
    "extracted_features = []\n",
    "\n",
    "def hook_function(module, input, output):\n",
    "    extracted_features.append(output.clone().detach())\n",
    "\n",
    "# Register the hook on the fc2 layer\n",
    "hook = model.fc2.register_forward_hook(hook_function)\n",
    "\n",
    "# Run a forward pass to trigger the hook\n",
    "model_output = model(X)\n",
    "X_fc2 = extracted_features[0]  # Extracted features\n",
    "print(\"The data after fc2 has the shape: \", X_fc2.shape)\n",
    "\n",
    "# Apply t-SNE on the fc2 features\n",
    "X_embeded_fc2 = tsne.fit_transform(X_fc2)\n",
    "\n",
    "# Plot the t-SNE results for fc2 features\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.scatterplot(x=X_embeded_fc2[:, 0], y=X_embeded_fc2[:, 1], hue=Y, palette=\"deep\")\n",
    "plt.title(\"t-SNE on MNIST Features from fc2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned features are clearly more separated then the raw pixel features, especially for digits 4 and 9, which enabled the network to make a better prediction!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "COMP6013-UnitPractical.ipynb",
   "provenance": [
    {
     "file_id": "1gVlyD2BLYgxtMnNkp8-0setRErAsKipI",
     "timestamp": 1648968941055
    }
   ]
  },
  "kernelspec": {
   "display_name": "gns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
